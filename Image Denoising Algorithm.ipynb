{"cells":[{"metadata":{"_uuid":"dd20f416-cde9-4513-8d96-980ad1e8413a","_cell_guid":"6004ae96-ee85-4f46-9af7-fb774ccc3fee","trusted":true,"id":"kHwulZ7OQQ3d"},"cell_type":"code","source":"import numpy as np\nimport math\nfrom tensorflow import keras\nfrom keras.optimizers import RMSprop, Adagrad, Adam\nfrom keras.layers import Conv2D, Input, Dense, Dropout, MaxPool2D, UpSampling2D\nfrom keras.layers import Conv2DTranspose, BatchNormalization, add, LeakyReLU\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nfrom keras.callbacks import ModelCheckpoint\nimport keras.layers as layers\nfrom keras.initializers import orthogonal\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60c505ef-aa92-4e90-9097-a35d36cb16e8","_cell_guid":"79bc2650-9552-4ba3-9844-5a6a9c29af85","trusted":true,"id":"6OWD-POoQVy0"},"cell_type":"code","source":"(cifar_train, _), (cifar_test, _) = cifar10.load_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61f7ed54-8635-4601-a83c-f928809c5c21","_cell_guid":"4ee3663b-6f0f-4a9d-89d1-a12358edc129","trusted":true,"id":"6b9RATLJQWO-"},"cell_type":"code","source":"size = 32\nchannel = 3\n# scaling input data\ncifar_train = cifar_train / 255\ncifar_test = cifar_test / 255\n\n# Adding noise mean = 0, std = 0.3\nnoise = 0.3\ncifar_train_noise = cifar_train + noise * np.random.normal(0, 0.3, size=cifar_train.shape) \ncifar_test_noise = cifar_test + noise * np.random.normal(0, 0.3, size=cifar_test.shape)\n\ncifar_train_noise = np.clip(cifar_train_noise, 0, 1)\ncifar_test_noise = np.clip(cifar_test_noise, 0, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42b9e14e-e251-4811-9df8-001e25ad9ac8","_cell_guid":"c37a03dc-accb-4f1e-8a93-4f953aadd982","trusted":true,"id":"-lh2XNteQWZt","outputId":"7475bcf1-b363-407a-9be5-1450e522109f"},"cell_type":"code","source":"# Visualize few training images with their noisy images\n\nrows = 2 # defining no. of rows in figure\ncols = 6# defining no. of colums in figure\n\nf = plt.figure(figsize=(2*cols,2*rows*2)) # defining a figure \n\nfor i in range(rows):\n    for j in range(cols): \n        f.add_subplot(rows*2,cols, (2*i*cols)+(j+1)) # adding sub plot to figure on each iteration\n        plt.imshow(cifar_train_noise[i*cols + j]) \n        plt.axis(\"off\")\n        \n    for j in range(cols): \n        f.add_subplot(rows*2,cols,((2*i+1)*cols)+(j+1)) # adding sub plot to figure on each iteration\n        plt.imshow(cifar_train[i*cols + j]) \n        plt.axis(\"off\")\n        \nf.suptitle(\"Sample Training Data\",fontsize=18)\nplt.savefig(\"Cifar-trian.png\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa560c7a-1767-4ce2-8584-de65c55b7da9","_cell_guid":"45f49d70-edbc-4f06-b014-7c7682043561","trusted":true,"id":"huigSEy0QWXS"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"154ea73d-0639-4bb7-a20f-68c72a1f8c9a","_cell_guid":"e4925d7c-5c42-4f7f-aa5e-24a001b88968","trusted":true,"id":"ePebb3o2QWUV"},"cell_type":"code","source":"inputs = Input(shape=(size,size,channel))\ndef Model_1():\n  x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n  x = BatchNormalization()(x)\n  x = MaxPool2D()(x)\n  x = Dropout(0.5)(x)\n  skip = Conv2D(32, 3, padding='same')(x) # skip connection for decoder\n  x = LeakyReLU()(skip)\n  x = BatchNormalization()(x)\n  x = MaxPool2D()(x)\n  x = Dropout(0.5)(x)\n  x = Conv2D(64, 3, activation='relu', padding='same')(x)\n  x = BatchNormalization()(x)\n  encoded = MaxPool2D()(x)\n\n  # Decoder\n  x = Conv2DTranspose(64, 3,activation='relu',strides=(2,2), padding='same')(encoded)\n  x = BatchNormalization()(x)\n  x = Dropout(0.5)(x)\n  x = Conv2DTranspose(32, 3, activation='relu',strides=(2,2), padding='same')(x)\n  x = BatchNormalization()(x)\n  x = Dropout(0.5)(x)\n  x = Conv2DTranspose(32, 3, padding='same')(x)\n  x = add([x,skip]) # adding skip connection\n  x = LeakyReLU()(x)\n  x = BatchNormalization()(x)\n  decoded = Conv2DTranspose(3, 3, activation='sigmoid',strides=(2,2), padding='same')(x)\n  return decoded\n\n\n\ndef Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n    prefix = f'block_{block_id}_'\n    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n    return x\n\ndef Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n    prefix = f'block_{block_id}_'\n    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n    return x\n\n\ndef Model_2():\n\n    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n    conv2 = Conv2DLayer(conv1, 64, 3, strides=2, padding='same', block_id=2)\n  \n    conv3 = Conv2DLayer(conv2, 128, 5, strides=2, padding='same', block_id=3)\n    \n    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n    conv5 = Conv2DLayer(conv4, 256, 5, strides=2, padding='same', block_id=5)\n    \n    conv6 = Conv2DLayer(conv5, 512, 3, strides=2, padding='same', block_id=6)\n    \n    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=2, padding='same', block_id=7)\n    \n    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=2, padding='same', block_id=9)\n    \n    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=2, padding='same', block_id=11)\n    \n    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=2, padding='same', block_id=13)\n    \n    skip4 = layers.concatenate([deconv4, conv1])\n    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n                       kernel_initializer=orthogonal(), name='final_conv')(skip4)\n\n    return conv10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6045c1e7-c4ce-4094-98b5-64aee7e1dfea","_cell_guid":"6b02cec3-59da-4702-b2e8-2226ea949224","trusted":true,"id":"brjUBCogQWMJ"},"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model_final.h5', verbose=1, save_best_only=True, save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c76643f4-6380-4654-b428-3887960b3240","_cell_guid":"25044b4f-219f-4fb9-b7d1-9b0a43dea0ca","trusted":true,"id":"KEQkqUl5QWIa","outputId":"7f1afebb-384c-4a35-a76f-be30d0992ef1"},"cell_type":"code","source":"# Encoder \ndecoder = Model_2()\n\n#decoder = Model_1()\nmodel = Model(inputs, decoder)\n\n\"\"\"\"\noptimizer = keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False\n)\n\noptimizer = keras.optimizers.Adagrad(\n    learning_rate=0.01,\n    initial_accumulator_value=0.1,\n    epsilon=1e-07\n)\n\"\"\"\n#optimizer = Adam(lr=0.001,decay=0.001/80)\noptimizer = keras.optimizers.Adamax(lr=0.001)\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\n\n#optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n\n#model_opt = Adam(lr_schedule)\nmodel.compile(optimizer=optimizer,loss='mean_squared_error')\n#model.compile(loss='mean_squared_error', optimizer = RMSprop())\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0ae5ef6-6fd9-4880-8413-5b09793a5670","_cell_guid":"7dfe8f06-5e7d-4581-ab08-21f27ac08968","trusted":true,"id":"xPphVvgxQWGL","outputId":"9adc674c-5688-4d93-f746-7b24045ce70c"},"cell_type":"code","source":"# Training\nepochs = 150\nbatch_size = 128\nhistory = model.fit(cifar_train_noise,\n                cifar_train,\n                epochs=epochs,\n                batch_size=batch_size,\n                shuffle=True,\n                validation_data=(cifar_test_noise, cifar_test),\n                callbacks=[checkpoint]\n               )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"631df377-3782-42e3-a6e8-af906ce31df9","_cell_guid":"5d110670-cb18-49a3-8cf3-3f35d09e3483","trusted":true,"id":"6CPaS5rcQWDi"},"cell_type":"code","source":"# Defining Figure\nf = plt.figure(figsize=(10,7))\nf.add_subplot()\n\n#Adding Subplot\nplt.plot(history.epoch, history.history['loss'], label = \"loss\") # Loss curve for training set\nplt.plot(history.epoch, history.history['val_loss'], label = \"val_loss\") # Loss curve for validation set\n\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\nplt.savefig(\"Loss_curve_cifar10.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47dfe2e4-80ed-4bc9-a48c-8076e012e50e","_cell_guid":"e94fa516-e6d5-4e2b-be03-2176b852e504","trusted":true},"cell_type":"code","source":"def mse(data_1, data_2):\n   return np.square(np.subtract(data_1, data_2)).mean()\n\ndef PSNR(data_1, data_2):\n    max_pixel = 1.0\n    return 10.0 * (1.0 / math.log(10)) * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a485fb5-1da9-4c6d-83f2-c9c113263023","_cell_guid":"1bbcfb69-580b-4e80-809a-0e507e21d542","trusted":true,"id":"XwfyjldPQWCQ"},"cell_type":"code","source":"import random\nimport tensorflow as tf\nfor i in range(20):\n  index = random.randint(0, 10000)\n  orig_images = cifar_test[index] \n  noised_original = cifar_test_noise[index]\n  noised_original_1 = noised_original.reshape(1,32,32,3)\n  test_desoided = model.predict(noised_original_1)\n  denoised_image  = test_desoided.reshape(32,32,3)\n\n  import matplotlib.pyplot as plt \n  %matplotlib inline\n  \n  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(9,3))\n\n  axes[0].imshow(orig_images)\n  axes[0].set_title('Original image')\n\n  axes[1].imshow(noised_original)\n  mse1 = round(mse(orig_images, noised_original), 5)\n  psnr1 = round(tf.image.psnr(orig_images,noised_original,max_val=1.0).numpy(), 5)\n  axes[1].set_title('Noised image \\n MSE = {} \\n PSNR = {}'.format(mse1, psnr1))\n  mse2 = round(mse(denoised_image, orig_images), 5)\n  psnr2 = round(tf.image.psnr(orig_images,denoised_image,max_val=1.0).numpy(), 2) \n  axes[2].imshow(denoised_image)\n  axes[2].set_title('Denoised image \\n MSE = {} \\n PSNR = {}'.format(mse2, psnr2))\n  plt.savefig(\"image\"+str(i)+\".png\")\n  plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}